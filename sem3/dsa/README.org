
#+DRAWERS: HIDDEN STATE
#+PROPERTY: header-args: lang           :varname value
#+PROPERTY: header-args:C++             :results output  :flags -std=c++17 -Wall --pedantic -Werror

* DSA
*** Table of contents
:PROPERTIES:
:TOC:      :include siblings :depth 3
:END:
:CONTENTS:
- [[#sorting-algorithms][Sorting algorithms]]
  - [[#selection-sort][Selection sort]]
    - [[#python-implementation][Python Implementation]]
    - [[#c-implementation][C Implementation]]
  - [[#insertion-sort][Insertion Sort]]
    - [[#python-implementation][Python Implementation]]
    - [[#c-implementation][C Implementation]]
  - [[#shell-sort][Shell sort]]
    - [[#python-implementation][Python Implementation]]
  - [[#merge-sort][Merge sort]]
    - [[#top-down-mergesort][Top Down MergeSort]]
    - [[#top-down-python-implementation][Top Down: Python Implementation]]
    - [[#top-down-cpp-implementation][Top Down: Cpp Implementation]]
    - [[#top-down-optimizations][Top Down: Optimizations]]
    - [[#bottom-up-mergesort][Bottom Up Mergesort]]
    - [[#notes-on-complexity][Notes on Complexity]]
:END:
*** Sorting algorithms
**** Selection sort
A simple minded solution, goes through each item and grabs the minimum.
The working part of array keeps decreasing by 1.
There are 3 parts, one is already sorted part, another is assumed part another is working part of array

// sorted----| A|-- Unsorted---|
| 1 | 2 | 3 | 5 | 4 | 9 | 10 |

the =i= is at =3= and it assumes =i= to be min and scans from =i+1= to =N= to try replace =i= (the assumed min)
Running time is (N-1)+(N-2)+(N-3) --> N^2/2 compares and N exchanges
***** Python Implementation

#+begin_src python :exports both :results output :tangle ~/dev/csit/sem3/dsa/sorting/selection_sort.py
  def sel_sort(array):
      N = len(array)
      for i in range(N):
          a_min = i
          for j in range(i+1, N):
              if array[j] < array[a_min]:
                  a_min = j
          exchange(a_min, i, array)
      return array

  def exchange(i, j, array):
      temp = array[i]
      array[i] = array[j]
      array[j] = temp

  print(sel_sort([5,4,3,4,0,5,2]))
#+end_src

#+RESULTS:
: [0, 2, 3, 4, 4, 5, 5]

***** C Implementation

#+begin_src C++ :main no :noweb yes :exports both :tangle ~/dev/csit/sem3/dsa/sorting/selection_sort.c :results output
  #include <stdio.h>

  void exchange(int i, int j, int array[]);

  void selection_sort(int array[], int N){
    for (int i=0; i<N; i++){
      int a_min = i;
      for(int j=i+1; j<N; j++)
        if (array[j] < array[a_min])
          a_min = j;
      exchange(i, a_min, array);
    }
  }

  void exchange(int i, int j, int array[]){
    int temp = array[i];
    array[i] = array[j];
    array[j] = temp;
  }

  int main(){
    int array[] = {5,3,0,4,2,5};
    int N = sizeof(array)/sizeof(int);
    selection_sort(array, N);
    for (int i=0; i<N; i++){
      printf("%d ", array[i]);
    }
  }
#+end_src

#+RESULTS:
: 0 2 3 4 5 5

**** Insertion Sort
This is similar to selection, there are two parts sorted and unsorted that moves by +1 on each iteration.
So theoritically on worst case both have similar N^2/2 running times.

Insertion sort focuses on the left part, it just takes one item from unsorted and then proceeds to sort the left part.
If we do impartial random analysis using randomly sorted data, insertion sort has better performance due to its design suited for nature of data.

Insertion sort, takes an item then traverse back the list to index 0, swapping all prev item greater than it.

Generally performs, N^2/4 (2 times faster than selection) on randomly sorted Data.
For, sorted data, its linear time i.e N-1 (every item except the first is compared and 0 exchanges).

The biggest benefit of insertion sort is in partially sorted data, (for eg in excel sheet of 1000 rows you add few unsorted rows) then whole column will be sorted in linear time.

***** Python Implementation

#+begin_src python :exports both :results output :tangle ~/dev/csit/sem3/dsa/sorting/insertion_sort.py
  def insertion_sort(array):
      N = len(array)
      for i in range(N):
          for j in range(i, 0, -1):
              if array[j] < array[j-1]:
                  exchange(j, j-1, array)
      return array

  def exchange(i, j, array):
      temp = array[i]
      array[i] = array[j]
      array[j] = temp

  print(insertion_sort([6,3,2,0,10,4,2]))
#+end_src

#+RESULTS:
: [0, 2, 2, 3, 4, 6, 10]

***** C Implementation

#+begin_src C++ :main no :noweb yes :exports both :tangle ~/dev/csit/sem3/dsa/sorting/insertion_sort.c :results output
  #include <stdio.h>

  void exchange(int i, int j, int array[]);

  void insertion_sort(int array[], int N){
    for (int i=0; i<N; i++)
      for(int j=i; j>0; j--)
        if (array[j] < array[j-1])
          exchange(j, j-1, array);
  }

  void exchange(int i, int j, int array[]){
    int temp = array[i];
    array[i] = array[j];
    array[j] = temp;
  }

  int main(){
    int array[] = {5,3,0,4,2,5};
    int N = sizeof(array)/sizeof(int);
    insertion_sort(array, N);
    for (int i=0; i<N; i++){
      printf("%d ", array[i]);
    }
  }
#+end_src

#+RESULTS:
: 0 2 3 4 5 5

**** Shell sort
We use h-sort increments to partially sort the array. We can use insertion sorting for that.
For a shell sort of 7-3-1
We jump to the 7th item, compare it with the item 7 place before it (i.e 0th/first) item. Then continue the process for 7+i item where (i=1,2,3...,N).
Then we do same for 3 and 1 then the array is sorted.

7-3-1 is an example combination and its still unknown what the ideal combination is.
The usual formula is 3x+1,
Shell originally in 1959 proprosed power of 2 - 1 which is worser.

Sedgewick proposes : 1, 5, 19, 41, 109, 209, 505, 929, 2161, 3905, ... acc to his empirical analysis which performs better.

With 3x+1, we get running time of N^1.5. But a comprehensive model has not been developed so it could even be nearer to NlogN

Power of shell sort is it uses insertion sort underhood so still simpler to implement and fast for smaller N.
- fast for smaller subarrays used in bzip2, linux/kernel/groups.c
- used in embedding devices for low footprint code.

Interesting as a best increment sequence is yet remaining to be discovered.

***** Python Implementation
#+begin_src python :exports both :results output :tangle ~/dev/csit/sem3/dsa/sorting/shell_sort.py
  def shell_sort(array):
      N = len(array)
      # Compute the last increment
      h = 1
      while (h < N/3):
          h = 3*h + 1 # The 3x + 1 increment sequence

      while (h >= 1):
          for i in range(h, N):
              for j in range(i, 0, -h):
                  if j >= h and array[j] < array[j-h]:
                      array[j], array[j-h] = array[j-h], array[j]
          h = int(h/3)
      return array

  print(shell_sort([5,6,4,3,0,2,3]))
#+end_src

#+RESULTS:
: [0, 2, 3, 3, 4, 5, 6]

**** Merge sort
***** Top Down MergeSort
The core concept is merging, ie taking two ordered list and creating a third ordered one.
this merging process should take a linear time and comparision should take constant time as long as array index access is guarenteed to be constant.

The rest process is just recursive function calls (TOP DOWN APPROACH).

The interesting bits are =in-place merge= and =extra optimizations=
- In-place merge is required to reduce the space complexity since merge sort requires to have an auxillary copy of array proportional to N.
- However, doing this in-place in a single array is very complicated process and simple process to implement, if any, is yet to be discovered.

***** Top Down: Python Implementation

#+begin_src python :exports both :results output :tangle ~/dev/csit/sem3/dsa/sorting/merge_sort.py
  def merge(array, aux, mid, low, high):
      """Assumes array is sorted from 0 to mid and mid+1 to N"""
      for i in range(low, high+1): # Copy operation
          aux[i] = array[i]
      # i points to A's first, j to B's first and K to aux array's first
      i, j = low, mid+1
      for k in range(low, high+1):
          if i > mid:
              array[k] = aux[j]
              j += 1
              continue
          elif j > high:
              array[k] = aux[i]
              i+=1
              continue
          else:
              if aux[i] < aux[j]:
                  array[k] = aux[i]
                  i+=1
              else:
                  array[k] = aux[j]
                  j+=1

  def mergesort(array, aux, low, high):
      if low >= high:
          return
      mid = int(low + (high-low)/2)
      mergesort(array, aux, low, mid)
      mergesort(array,aux, mid+1, high)
      merge(array, aux, mid, low, high)

  def sort(array):
      aux = array[:]
      mergesort(array, aux, 0, len(array)-1)
      return array

  print(sort([4,2,0,5,2,9,1,0, 3]))
#+end_src

#+RESULTS:
: [0, 0, 1, 2, 2, 3, 4, 5, 9]

***** Top Down: Cpp Implementation

#+begin_src C++ :main no :noweb yes :exports both :tangle ~/dev/csit/sem3/dsa/sorting/merge_sort.c :results output
  #include <stdio.h>

  void merge(int array[], int aux[], int mid, int low, int high){
    // Takes an array, which is sorted from low to mid and mid+1 to high
    // This function merges these two halves together to get an ordered array

    // Copy operation
    for (int k=low; k<=high; k++)
      aux[k] = array[k];

    int i = low, j = mid+1;
    for (int k=low; k<=high; k++)
      if (i > mid) array[k] = aux[j++];
      else if (j > high) array[k] = aux[i++];
      else if (aux[i] < aux[j]) array[k] = aux[i++];
      else array[k] = aux[j++];
  }

  void mergesort(int array[], int aux[], int low, int high){
    if (low >= high) return;

    int mid = (int) low + (high - low) / 2;

    mergesort(array, aux, low, mid);
    mergesort(array, aux, mid+1, high);
    merge(array, aux, mid, low, high);
  }

  void sort(int array[], int N){
    int aux[N];
    mergesort(array, aux, 0, N-1);
  }

  int main(){
    int array[] = {1,2,3,9,0,2,5,3,0,6};
    int N = sizeof(array)/sizeof(int);

    sort(array, N);
    for (int i=0; i<N; i++){
      printf("%d ", array[i]);
    }
  }
#+end_src

#+RESULTS:
: 0 0 1 2 2 3 3 5 6 9

***** Top Down: Optimizations
****** Check if array is already sorted
This check is done by comparing the end of first half (largest item in first half) and start of second half (smallest item). If =less than or equal to= check passes then array is already sorted.
- Reported 10% slower than recursive top down one (for java impl on most systems).

#+begin_src python :exports code :results output
  def mergesort(array, aux, low, high):
      if low >= high:
          return
      mid = int(low + (high-low)/2)
      mergesort(array, aux, low, mid)
      mergesort(array,aux, mid+1, high)
      # Avoid merge if already sorted
      if array[mid] <= array[mid+1]:
          return
      merge(array, aux, mid, low, high)
#+end_src

#+RESULTS:

****** Use insertion sort for smaller sub arrays
- Mergesort has too many overhead for tiny arrays.
- Cutoff to insertion sort for ~ 7 items.

#+begin_src python :exports code :results output
  def mergesort(array, aux, low, high):
      if high <= (low + CUTOFF - 1):
          insertion_sort(array, low, high)
          return
      mid = int(low + (high-low)/2)
      mergesort(array, aux, low, mid)
      mergesort(array,aux, mid+1, high)
      # Avoid merge if already sorted
      if array[mid] <= array[mid+1]:
          return
      merge(array, aux, mid, low, high)
#+end_src

****** Eliminate Copy of Auxillary Array (save time but not space)

Switch array and aux for each recursion in mergesort
Similarly in merge,
- remove the code for copying and move it to sort() that calls mergesort
- Switch roles, merge array to aux.
Finally in sort,
- Copy array to aux before calling mergesort

#+begin_src python :exports code :results output
  def mergesort(array, aux, low, high):
      if high <= (low + CUTOFF - 1):
          insertion_sort(array, low, high)
          return
      mid = int(low + (high-low)/2)
      mergesort(aux, array, low, mid)     # Switched here
      mergesort(aux, array, mid+1, high)  # Switched here
      # Avoid merge if already sorted
      if array[mid] <= array[mid+1]:
          return
      merge(array, aux, mid, low, high)

  def merge(array, aux, mid, low, high):
      """Assumes array is sorted from 0 to mid and mid+1 to N"""

      #for i in range(low, high+1): # Copy operation  # Deleted line
      #    aux[i] = array[i]                          # Deleted line

      # i points to A's first, j to B's first and K to aux array's first
      i, j = low, mid+1
      for k in range(low, high+1):
          if i > mid:
              aux[k] = array[j]        # Switched here
              j += 1
              continue
          elif j > high:
              aux[k] = array[i]
              i+=1
              continue
          else:
              if array[i] < array[j]:  # Switched here
                  aux[k] = array[i]    # Switched here
                  i+=1
              else:
                  aux[k] = array[j]    #  Switched here
                  j+=1

  def sort(array):
      aux = array[:]
      mergesort(array, aux, 0, len(array)-1)
      return array
#+end_src

***** Bottom Up Mergesort
Inside the mergesort function the recursive calls are replaced by iterative loop with intervals first starting at 1,2...,N.
Eg lets start at size 1, it can be produced by
- Combining 1st and 2nd item, 3rd and 4th and so on
Then for size 2,
- 1-2 is merged with 3-4 and so on

#+begin_src python :exports code :results output
    def merge(array, aux, mid, low, high):
        # same code
        pass

    def sort():
        # Deleted function
        pass

    def mergesort(array):
        N = len(array)
        aux = []
        sz = 1
        while sz < N:
            low = 0
            while low < N - sz:
                # if at the end of list take whichever feasible
                high = min(lo+sz+sz-1, N-1)
                merge(a, aux, lo, lo+sz-1, high)
                low += sz + sz
            sz += sz
#+end_src

***** Notes on Complexity
*Computational Complexity Analysis*
This analysis framework consists mainly of
- Upper Bound: The running time guarenteed by Algorithm in question (here mergesort)
- Lower Bound: Theoritical proven lowest cost time needed by algorithm X
- Optimum Algorithm: Algorithm X where Upper Bound ~ Lower Bound

  The Lower Bound of sorting is proven to be ~N Log N~ and =mergesort= achieves this. However it doesnot achieve optimum *space complexity*

So a better algorithm than merge sort would not be faster than mergesort (its impossible) but the one that takes less space. We'll look at those algorithm below.
