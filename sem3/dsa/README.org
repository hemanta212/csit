
#+DRAWERS: HIDDEN STATE
#+PROPERTY: header-args: lang           :varname value
#+PROPERTY: header-args:C++             :results output  :flags -std=c++17 -Wall --pedantic -Werror

* DSA
*** Table of contents
:PROPERTIES:
:TOC:      :include siblings :depth 3
:END:
:CONTENTS:
- [[#sorting-algorithms][Sorting algorithms]]
  - [[#selection-sort][Selection sort]]
    - [[#python-implementation][Python Implementation]]
    - [[#c-implementation][C Implementation]]
  - [[#insertion-sort][Insertion Sort]]
    - [[#python-implementation][Python Implementation]]
    - [[#c-implementation][C Implementation]]
  - [[#shell-sort][Shell sort]]
    - [[#python-implementation][Python Implementation]]
  - [[#merge-sort][Merge sort]]
    - [[#top-down-mergesort][Top Down MergeSort]]
    - [[#top-down-python-implementation][Top Down: Python Implementation]]
    - [[#top-down-cpp-implementation][Top Down: Cpp Implementation]]
    - [[#top-down-optimizations][Top Down: Optimizations]]
    - [[#bottom-up-mergesort][Bottom Up Mergesort]]
    - [[#notes-on-complexity][Notes on Complexity]]
  - [[#quick-sort][Quick sort]]
    - [[#python-implementation][Python Implementation]]
    - [[#c-implementation][C Implementation]]
    - [[#implementation-details][Implementation Details]]
    - [[#running-time-analysis][Running Time Analysis]]
    - [[#improvements][Improvements]]
  - [[#heap-sort][Heap Sort]]
:END:
*** Sorting algorithms
**** Selection sort
A simple minded solution, goes through each item and grabs the minimum.
The working part of array keeps decreasing by 1.
There are 3 parts, one is already sorted part, another is assumed part another is working part of array

// sorted----| A|-- Unsorted---|
| 1 | 2 | 3 | 5 | 4 | 9 | 10 |

the =i= is at =3= and it assumes =i= to be min and scans from =i+1= to =N= to try replace =i= (the assumed min)
Running time is (N-1)+(N-2)+(N-3) --> N^2/2 compares and N exchanges
***** Python Implementation

#+begin_src python :exports both :results output :tangle ~/dev/csit/sem3/dsa/sorting/selection_sort.py
  def sel_sort(array):
      N = len(array)
      for i in range(N):
          a_min = i
          for j in range(i+1, N):
              if array[j] < array[a_min]:
                  a_min = j
          exchange(a_min, i, array)
      return array

  def exchange(i, j, array):
      temp = array[i]
      array[i] = array[j]
      array[j] = temp

  print(sel_sort([5,4,3,4,0,5,2]))
#+end_src

#+RESULTS:
: [0, 2, 3, 4, 4, 5, 5]

***** C Implementation

#+begin_src C++ :main no :exports both :tangle ~/dev/csit/sem3/dsa/sorting/selection_sort.c :results output
  #include <stdio.h>

  void exchange(int i, int j, int array[]);

  void selection_sort(int array[], int N){
    for (int i=0; i<N; i++){
      int a_min = i;
      for(int j=i+1; j<N; j++)
        if (array[j] < array[a_min])
          a_min = j;
      exchange(i, a_min, array);
    }
  }

  void exchange(int i, int j, int array[]){
    int temp = array[i];
    array[i] = array[j];
    array[j] = temp;
  }

  int main(){
    int array[] = {5,3,0,4,2,5};
    int N = sizeof(array)/sizeof(int);
    selection_sort(array, N);
    for (int i=0; i<N; i++){
      printf("%d ", array[i]);
    }
  }
#+end_src

#+RESULTS:
: 0 2 3 4 5 5

**** Insertion Sort
This is similar to selection, there are two parts sorted and unsorted that moves by +1 on each iteration.
So theoritically on worst case both have similar N^2/2 running times.

Insertion sort focuses on the left part, it just takes one item from unsorted and then proceeds to sort the left part.
If we do impartial random analysis using randomly sorted data, insertion sort has better performance due to its design suited for nature of data.

Insertion sort, takes an item then traverse back the list to index 0, swapping all prev item greater than it.

Generally performs, N^2/4 (2 times faster than selection) on randomly sorted Data.
For, sorted data, its linear time i.e N-1 (every item except the first is compared and 0 exchanges).

The biggest benefit of insertion sort is in partially sorted data, (for eg in excel sheet of 1000 rows you add few unsorted rows) then whole column will be sorted in linear time.

***** Python Implementation

#+begin_src python :exports both :results output :tangle ~/dev/csit/sem3/dsa/sorting/insertion_sort.py
  def insertion_sort(array):
      N = len(array)
      for i in range(N):
          for j in range(i, 0, -1):
              if array[j] < array[j-1]:
                  exchange(j, j-1, array)
      return array

  def exchange(i, j, array):
      temp = array[i]
      array[i] = array[j]
      array[j] = temp

  print(insertion_sort([6,3,2,0,10,4,2]))
#+end_src

#+RESULTS:
: [0, 2, 2, 3, 4, 6, 10]

***** C Implementation

#+begin_src C++ :main no :exports both :tangle ~/dev/csit/sem3/dsa/sorting/insertion_sort.c :results output
  #include <stdio.h>

  void exchange(int i, int j, int array[]);

  void insertion_sort(int array[], int N){
    for (int i=0; i<N; i++)
      for(int j=i; j>0; j--)
        if (array[j] < array[j-1])
          exchange(j, j-1, array);
  }

  void exchange(int i, int j, int array[]){
    int temp = array[i];
    array[i] = array[j];
    array[j] = temp;
  }

  int main(){
    int array[] = {5,3,0,4,2,5};
    int N = sizeof(array)/sizeof(int);
    insertion_sort(array, N);
    for (int i=0; i<N; i++){
      printf("%d ", array[i]);
    }
  }
#+end_src

#+RESULTS:
: 0 2 3 4 5 5

**** Shell sort
We use h-sort increments to partially sort the array. We can use insertion sorting for that.
For a shell sort of 7-3-1
We jump to the 7th item, compare it with the item 7 place before it (i.e 0th/first) item. Then continue the process for 7+i item where (i=1,2,3...,N).
Then we do same for 3 and 1 then the array is sorted.

7-3-1 is an example combination and its still unknown what the ideal combination is.
The usual formula is 3x+1,
Shell originally in 1959 proprosed power of 2 - 1 which is worser.

Sedgewick proposes : 1, 5, 19, 41, 109, 209, 505, 929, 2161, 3905, ... acc to his empirical analysis which performs better.

With 3x+1, we get running time of N^1.5. But a comprehensive model has not been developed so it could even be nearer to NlogN

Power of shell sort is it uses insertion sort underhood so still simpler to implement and fast for smaller N.
- fast for smaller subarrays used in bzip2, linux/kernel/groups.c
- used in embedding devices for low footprint code.

Interesting as a best increment sequence is yet remaining to be discovered.

***** Python Implementation
#+begin_src python :exports both :results output :tangle ~/dev/csit/sem3/dsa/sorting/shell_sort.py
  def shell_sort(array):
      N = len(array)
      # Compute the last increment
      h = 1
      while (h < N/3):
          h = 3*h + 1 # The 3x + 1 increment sequence

      while (h >= 1):
          for i in range(h, N):
              for j in range(i, 0, -h):
                  if j >= h and array[j] < array[j-h]:
                      array[j], array[j-h] = array[j-h], array[j]
          h = int(h/3)
      return array

  print(shell_sort([5,6,4,3,0,2,3]))
#+end_src

#+RESULTS:
: [0, 2, 3, 3, 4, 5, 6]

**** Merge sort
***** Top Down MergeSort
The core concept is merging, ie taking two ordered list and creating a third ordered one.
this merging process should take a linear time and comparision should take constant time as long as array index access is guarenteed to be constant.

The rest process is just recursive function calls (TOP DOWN APPROACH).

The interesting bits are =in-place merge= and =extra optimizations=
- In-place merge is required to reduce the space complexity since merge sort requires to have an auxillary copy of array proportional to N.
- However, doing this in-place in a single array is very complicated process and simple process to implement, if any, is yet to be discovered.

***** Top Down: Python Implementation

#+begin_src python :exports both :results output :tangle ~/dev/csit/sem3/dsa/sorting/merge_sort.py
  def merge(array, aux, mid, low, high):
      """Assumes array is sorted from 0 to mid and mid+1 to N"""
      for i in range(low, high+1): # Copy operation
          aux[i] = array[i]
      # i points to A's first, j to B's first and K to aux array's first
      i, j = low, mid+1
      for k in range(low, high+1):
          if i > mid:
              array[k] = aux[j]
              j += 1
              continue
          elif j > high:
              array[k] = aux[i]
              i+=1
              continue
          else:
              if aux[i] < aux[j]:
                  array[k] = aux[i]
                  i+=1
              else:
                  array[k] = aux[j]
                  j+=1

  def mergesort(array, aux, low, high):
      if low >= high:
          return
      mid = int(low + (high-low)/2)
      mergesort(array, aux, low, mid)
      mergesort(array,aux, mid+1, high)
      merge(array, aux, mid, low, high)

  def sort(array):
      aux = array[:]
      mergesort(array, aux, 0, len(array)-1)
      return array

  print(sort([4,2,0,5,2,9,1,0, 3]))
#+end_src

#+RESULTS:
: [0, 0, 1, 2, 2, 3, 4, 5, 9]

***** Top Down: Cpp Implementation

#+begin_src C++ :main no :exports both :tangle ~/dev/csit/sem3/dsa/sorting/merge_sort.c :results output
  #include <stdio.h>

  void merge(int array[], int aux[], int mid, int low, int high){
    // Takes an array, which is sorted from low to mid and mid+1 to high
    // This function merges these two halves together to get an ordered array

    // Copy operation
    for (int k=low; k<=high; k++)
      aux[k] = array[k];

    int i = low, j = mid+1;
    for (int k=low; k<=high; k++)
      if (i > mid) array[k] = aux[j++];
      else if (j > high) array[k] = aux[i++];
      else if (aux[i] < aux[j]) array[k] = aux[i++];
      else array[k] = aux[j++];
  }

  void mergesort(int array[], int aux[], int low, int high){
    if (low >= high) return;

    int mid = (int) low + (high - low) / 2;

    mergesort(array, aux, low, mid);
    mergesort(array, aux, mid+1, high);
    merge(array, aux, mid, low, high);
  }

  void sort(int array[], int N){
    int aux[N];
    mergesort(array, aux, 0, N-1);
  }

  int main(){
    int array[] = {1,2,3,9,0,2,5,3,0,6};
    int N = sizeof(array)/sizeof(int);

    sort(array, N);
    for (int i=0; i<N; i++){
      printf("%d ", array[i]);
    }
  }
#+end_src

#+RESULTS:
: 0 0 1 2 2 3 3 5 6 9

***** Top Down: Optimizations
****** Check if array is already sorted
This check is done by comparing the end of first half (largest item in first half) and start of second half (smallest item). If =less than or equal to= check passes then array is already sorted.
- Reported 10% slower than recursive top down one (for java impl on most systems).

#+begin_src python :exports code :results output
  def mergesort(array, aux, low, high):
      if low >= high:
          return
      mid = int(low + (high-low)/2)
      mergesort(array, aux, low, mid)
      mergesort(array,aux, mid+1, high)
      # Avoid merge if already sorted
      if array[mid] <= array[mid+1]:
          return
      merge(array, aux, mid, low, high)
#+end_src

#+RESULTS:

****** Use insertion sort for smaller sub arrays
- Mergesort has too many overhead for tiny arrays.
- Cutoff to insertion sort for ~ 7 items.

#+begin_src python :exports code :results output
  def mergesort(array, aux, low, high):
      if high <= (low + CUTOFF - 1):
          insertion_sort(array, low, high)
          return
      mid = int(low + (high-low)/2)
      mergesort(array, aux, low, mid)
      mergesort(array,aux, mid+1, high)
      # Avoid merge if already sorted
      if array[mid] <= array[mid+1]:
          return
      merge(array, aux, mid, low, high)
#+end_src

****** Eliminate Copy of Auxillary Array (save time but not space)

Switch array and aux for each recursion in mergesort
Similarly in merge,
- remove the code for copying and move it to sort() that calls mergesort
- Switch roles, merge array to aux.
Finally in sort,
- Copy array to aux before calling mergesort

#+begin_src python :exports code :results output
  def mergesort(array, aux, low, high):
      if high <= (low + CUTOFF - 1):
          insertion_sort(array, low, high)
          return
      mid = int(low + (high-low)/2)
      mergesort(aux, array, low, mid)     # Switched here
      mergesort(aux, array, mid+1, high)  # Switched here
      # Avoid merge if already sorted
      if array[mid] <= array[mid+1]:
          return
      merge(array, aux, mid, low, high)

  def merge(array, aux, mid, low, high):
      """Assumes array is sorted from 0 to mid and mid+1 to N"""

      #for i in range(low, high+1): # Copy operation  # Deleted line
      #    aux[i] = array[i]                          # Deleted line

      # i points to A's first, j to B's first and K to aux array's first
      i, j = low, mid+1
      for k in range(low, high+1):
          if i > mid:
              aux[k] = array[j]        # Switched here
              j += 1
              continue
          elif j > high:
              aux[k] = array[i]
              i+=1
              continue
          else:
              if array[i] < array[j]:  # Switched here
                  aux[k] = array[i]    # Switched here
                  i+=1
              else:
                  aux[k] = array[j]    #  Switched here
                  j+=1

  def sort(array):
      aux = array[:]
      mergesort(array, aux, 0, len(array)-1)
      return array
#+end_src

***** Bottom Up Mergesort
Inside the mergesort function the recursive calls are replaced by iterative loop with intervals first starting at 1,2...,N.
Eg lets start at size 1, it can be produced by
- Combining 1st and 2nd item, 3rd and 4th and so on
Then for size 2,
- 1-2 is merged with 3-4 and so on

#+begin_src python :exports code :results output
    def merge(array, aux, mid, low, high):
        # same code
        pass

    def sort():
        # Deleted function
        pass

    def mergesort(array):
        N = len(array)
        aux = []
        sz = 1
        while sz < N:
            low = 0
            while low < N - sz:
                # if at the end of list take whichever feasible
                high = min(lo+sz+sz-1, N-1)
                merge(a, aux, lo, lo+sz-1, high)
                low += sz + sz
            sz += sz
#+end_src

***** Notes on Complexity
*Computational Complexity Analysis*
This analysis framework consists mainly of
- Upper Bound: The running time guarenteed by Algorithm in question (here mergesort)
- Lower Bound: Theoritical proven lowest cost time needed by algorithm X
- Optimum Algorithm: Algorithm X where Upper Bound ~ Lower Bound

  The Lower Bound of sorting is proven to be ~N Log N~ and =mergesort= achieves this. However it doesnot achieve optimum *space complexity*

So a better algorithm than merge sort would not be faster than mergesort (its impossible) but the one that takes less space. We'll look at those algorithm below.

**** Quick sort
Quick sort consists of following steps:
- Shuffle the array
- Choose a random point as partitioning element (we can choose first one since array is shuffled)
- Then have two counters i and j, starting from each ends of array. i from index 1 and j from last i.e index N-1
- Keep incrementing i till it encounters element greater than or equal to partioning element, and keep decrementing j till it encounters element less than partitioning element.
- Remember, both i and j need not stop if encountered element equal to partitioning element, they only need to stop on greater/lesser elements but it still useful to keep them on one side only.
- When i and j both stop, they simply swap element and continue the process. if only one stops we wait for another to stop.
- Now, simultaneously we check if i and j cross, we simply check if j less than i. Then we stop the loop.
- Finally we swap the partitioning element with j.
- What we have is a partitioning element in an array whose left side is element less than it and right side are elements greater than it.
- Doing this process recursively yields a quick-sorted array.

***** Python Implementation

#+begin_src python :exports both :results output :tangle ~/dev/csit/sem3/dsa/sorting/quick_sort.py
  import random

  def partition(array, lo, hi):
      par, i, j = array[lo], lo+1, hi
      while True:
          while array[i] <= par:
              if i == hi:
                  break
              i += 1

          while array[j] > par:
              j -= 1
              if j == lo:
                  break

          if j <= i:
              break
          array[j], array[i] = array[i], array[j]

      array[lo], array[j] = array[j], array[lo]
      return j

  def quicksort(array, lo, hi):
      if hi <= lo:
          return
      j = partition(array, lo, hi)
      quicksort(array, lo, j-1)
      quicksort(array, j+1, hi)

  def sort(array):
      random.shuffle(array)
      quicksort(array, 0, len(array)-1)
      return array

  print(sort([5,4,3,0,2,7,9,1,5]))
  print(sort([0,2,1]))
  print(sort([3,1,2]))
  print(sort([3,1]))
  print(sort([1,3]))
#+end_src

#+RESULTS:
: [0, 1, 2, 3, 4, 5, 5, 7, 9]
: [0, 1, 2]
: [1, 2, 3]
: [1, 3]
: [1, 3]
: [0, 2]

***** C Implementation
#+begin_src C++ :main no :exports both :results output :tangle ~/dev/csit/sem3/dsa/sorting/quick_sort.c
  #include <stdio.h>

  void exchg(int array[], int i, int j);

  int partition(int array[], int lo, int hi){
    int i = lo+1, j = hi, par=array[lo];
    while(1){
        while(array[i] <= par){
          i++;
          if (i == hi) { break; }
       }

        while(array[j] > par){
          j--;
          if (j == lo){ break;}
       }

        if (j <= i) { break;}
        exchg(array, i, j);
    }
    exchg(array, lo, j);
    return j;
  }

  void quicksort(int array[], int lo, int hi){
    if (hi <= lo)
      return;
    int j = partition(array, lo, hi);
    quicksort(array, lo, j-1);
    quicksort(array, j+1, hi);
   }

  void sort(int array[], int N){
     // TODO shuffle array in c
     quicksort(array, 0, N-1);
  }

  void exchg(int array[], int i, int j){
        int temp = array[i];
        array[i] = array[j];
        array[j] = temp;
  }

  int main(){
    int array[] = {3, 0};
    int N = sizeof(array)/sizeof(int);
    sort(array, N);

    for(int i=0; i<N; i++){
      printf("%d ", array[i]);
    }
    return 0;
  }
#+end_src

#+RESULTS:
: 0 3

***** Implementation Details
****** In place partitioning
Quick sort doesnot take extra space as mergesort, however we could ues duplicated array to make it more easier and stable. However, then it becomes space expensive.
****** Terminating the loop
Testing whether the pointer cross is trickier then it seems.
****** Redundant bounds
The bound check =if i equal to high= is necessary but checking ~if j equals lo~ is redundant.
****** Handling duplicates/Equal keys
When duplicate of partitioning key is present, it is (counter-intuitively) better to stop than to skip.

***** Running Time Analysis
- The best case for the sorting is ~Nlogn which is similar to merge sort. However most of times the we get 1.39NlogN which is faster than mergesort because data movement (excahnges) is less. Mostly its just incrementing i and j.

- The sorting is not stable, and we need to use extra array during partitioning to make it stable which has space costs.

- The worst case is when the array is already sorted, then its 1/2N^2 which is quadratic. Thus the importance of shuffling an array before applying quicksort. Also, the change of randomly shuffled array to be mostly sorted is very very low and can be ignored.

- Similarly, if it has lots of duplicates then the running time can go quadratic.


***** Improvements
****** Use insertion sort for small subarrays
Similarly implemented as mergesort, we delegate the sorting if the size is under CUTOFF value.
****** Choose median as partitioning element.
Median is the best choice.
We can estimate true median by taking median of sample.
We take median of 3 random items and choose that as partitioning value.
Improves performance about 10%.

**** Heap Sort
*NOTE:* Read priority queues first

*Heap Binary Tree*
A heap binary tree is a complete binary tree with max order guarenteed always, where a parent node is always greater in value than its children nodes, thus making the root node the largest item.

*Basic Plan*
- Create max-heap with all ~N~ keys.
- Repeatedly remove the maximum key.

+ We take a array with keys at random order
+ We know do inplace heap ordering on that array by supposing it as a binary heap.

  *Heap Construction:*
Build max heap using bottom-up method.

- A random key array is taken
- A node is by default heap ordered it has no children
- We visit each ~n-1~ leveled node (where ~n~ is no of levels of heap)
- We run sink operation to make sure the level and bottom level is ordered
- We move one level up and do the same ensuring all the lower levels are ordered.
- Finally we reach the root and sink it.

Now, once the heap is max oriented, we repeatedly execute the delMax operation removing the root with last element of array and sinking it to re-balance the tree. Until the tree is empty.

#+begin_src python :exports both :results output
  start_level = round(N/2)
  end_level = 0
  k = start_level
  while k >= end_level:
      sink(array, k, N)
#+end_src

#+begin_src python :exports both :results output
  while N>0:
      exchg(array, 0, N)
      N -= 1
      sink(a, 0, N);
#+end_src
